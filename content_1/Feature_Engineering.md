# 特征工程

## 1. 特征清洗
特征清洗主要是在数据进入特征工程的后续步骤之前，先确保所有数据干净，不带有异常值和后续无法处理的数据类型。

### 1.1 异常值处理
数据匹配/非法字符：检查数据表和目标变量的格式是否匹配。发现不匹配则判断其是否为有效数据（“1”而不是“ ”，“&…*”等非法字符），如果是有效数据则进行格式转换，否则剔除。还需要注意一些”非法空值“，比如空格，要用python中的nan替换。
* 无穷值：通常表现为inf,-inf,也有可能是很大的值，比如1e20这样的（不同数据源给的极大值不同），可先替换成空值再进一步处理。
* 不合理值：这个需要随着数据集的累计不断增加，对一些特定的特征加一些限制，做一个类似因子风控预警的模块。比如价格不可能是负数等

### 1.2  缺失值处理
* 数据填充：首先确定填充策略，不同的因子适合不同的填充方法，前值，滚动均值，KNN等。（sklearn Imputer）
（元素的填充函数，Data_filling_f,…..，参数：填充方法）
* 缺失值过多列：如果一列中的空值占了总行数的一定阈值（如80%），则该特征因子可以提供的信息过少，直接删去。如果这个特征的空值有实际意义，则二值化处理。
（先判断缺失值是否过多，_missing_value_，参数：特征名称、空值阈值。
先判断有没有超过阈值，没有就进入填充；超过阈值，判断特征名称是否在config的df里，是就按照二值化处理，否就删除）
Config：一列为空值有实际意义的特征名称，一列为二值化处理的阈值，二列为二值化处理的二值（上下）（元素的二值化函数：binarization，参数：二值化阈值，阈值上值，阈值下值）

### 1.3 数据遗漏
* 时间戳不匹配：有时会直接错过某个时间点的数据，导致一整行数据遗漏，且不以空值的形式出现。需要我们对每个频率/交易标的都能够有一个交易时间标准，对所有的数据都和这个交易时间进行匹配，若有遗漏则出发预警，与交易时间标准merge后再考虑填充。
（得到所有的日期序列或df1，在交易日期表中找到最早和最新的日期，得到df2，先判断长度是否一致，一致就进入(2)；不一致进行）

## 2. 特征构造
特征构造主要是产生衍生变量，所谓衍生变量是指对原始数据进行加工、特征组合，生成有具有含义的新变量(新特征)
构造原则：这个特征对目标是否有实际意义？如果有，特征的重要性如何？这个新构造的特征信息是否在其他特征体现过？

### 2.1 特征变换
* 连续数据离散化：二值化、分箱等，有时候特征值的范围比特征值本更重要，比如某个特征超过一定阈值的时候很要。
* 离散数据编码化：序号编码，one-hot编码，比如所在行业板块这样的信息，可能需要做编码。
* 特征转换：归一化，标准化，cox-box正态度化，以帮助模型更快的训练，对过偏的点进行纠正。

### 2.2 特征衍生
* 统计值构造法：通过统计单个或者多个变量的统计值(max,min,count,mean)等而形成新的特征。比如日内高频数据的统计量也可以当作一个日频特征。
* 函数构造法：平方(小数值—>大数值)、开平方(大数值—>小数值)、指数、对数、差分

### 2.3 特征交叉
* 条件式构造：特征A在特征B不同取值条件下的统计量。
* 笛卡尔积：直接对两个或多个特征进行组合，组合特征直接成为新的特征（连续特征需分箱）。
* GP-Learn：遗传算法，随机组合特征，在进行迭代筛选。

## 3. 特征筛选
当数据处理好之后，我们需要选择有意义的特征输入机器学习的模型进行训练，同时避免过多特征造成的的过拟合与训练时间消耗

### 3.1 特征选择
* 过滤法：过滤法通过使用一些统计量或假设检验结果为每个变量打分。得分较高的功能往往更加重要，因此应被包含在子集中，如采用方差，相关系数，互信息等。
* 嵌入法：先使用某些机器学习的算法和模型进行训练，得到各个特征的权值系数或者特征重要性，从大到小选择特征。
* 包裹法：封装方法将特征选择问题视作搜索问题，即其目标为从特征子集集合中搜索出一个最佳的子集，而这一子集在模型中表现最佳。
在每一步中，其在特征子集上训练模型，然后对其进行评估，并在下一步继续调整特征子集,重新训练评估，直到找到最佳子集或达到最大迭代次数为止

### 3.2 降维
* 主成分分析PCA，最小化重构误差
* 线性判别分析LDA，最大化类别可分性
* 判别训练discriminative training，最小化分类误差
* 立成分分析ICA，最大限度的使各特征之间独立
